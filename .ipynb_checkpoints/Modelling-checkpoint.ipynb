{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfda5fe-a38e-486f-bf34-893fe118d424",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c96760f-b68e-401e-a2a6-d69c9e90ae53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "802cd335-d59d-4c25-bf08-eee02baee785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>airline_name</th>\n",
       "      <th>NPS_category</th>\n",
       "      <th>NPS</th>\n",
       "      <th>language_info</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>uppercase_words</th>\n",
       "      <th>comma_count</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_mark_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>flesch_reading_score</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>2023-09-18 03:29:15</td>\n",
       "      <td>EasyJet sent text at 4.00 am day of flight hom...</td>\n",
       "      <td>easyjet</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>text rush organise transport effort implicatio...</td>\n",
       "      <td>194</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>5.878788</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>81.90</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2023-12-01 00:00:00</td>\n",
       "      <td>Its been a few years when I flew a lot in A...</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>asia vistara surprise swift immaculate steward...</td>\n",
       "      <td>608</td>\n",
       "      <td>109</td>\n",
       "      <td>74</td>\n",
       "      <td>5.527273</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>61.19</td>\n",
       "      <td>14.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>2018-09-09 20:37:11</td>\n",
       "      <td>one of the worst experiences with Air France e...</td>\n",
       "      <td>air france</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>ever bore carry duty inbound</td>\n",
       "      <td>204</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>6.580645</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>61.33</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>2019-12-23 14:00:19</td>\n",
       "      <td>Not a single star this airlines deserves .I lo...</td>\n",
       "      <td>egyptair</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>deserves last block respond mail operator harr...</td>\n",
       "      <td>464</td>\n",
       "      <td>87</td>\n",
       "      <td>64</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>74.39</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>2023-12-29 06:42:56</td>\n",
       "      <td>I was forced to pay 150-euro worth penalty for...</td>\n",
       "      <td>ryanair</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>penalty fail earth would dare season arrogant ...</td>\n",
       "      <td>240</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>58.58</td>\n",
       "      <td>10.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           overall_rating          review_date  \\\n",
       "0  Rated 1 out of 5 stars  2023-09-18 03:29:15   \n",
       "1                       9  2023-12-01 00:00:00   \n",
       "3  Rated 1 out of 5 stars  2018-09-09 20:37:11   \n",
       "4  Rated 1 out of 5 stars  2019-12-23 14:00:19   \n",
       "5  Rated 1 out of 5 stars  2023-12-29 06:42:56   \n",
       "\n",
       "                                         review_text airline_name  \\\n",
       "0  EasyJet sent text at 4.00 am day of flight hom...      easyjet   \n",
       "1     Its been a few years when I flew a lot in A...      Vistara   \n",
       "3  one of the worst experiences with Air France e...   air france   \n",
       "4  Not a single star this airlines deserves .I lo...     egyptair   \n",
       "5  I was forced to pay 150-euro worth penalty for...      ryanair   \n",
       "\n",
       "  NPS_category  NPS language_info  \\\n",
       "0    Detractor   -1            en   \n",
       "1     Promoter    1            en   \n",
       "3    Detractor   -1            en   \n",
       "4    Detractor   -1            en   \n",
       "5    Detractor   -1            en   \n",
       "\n",
       "                                          clean_text  text_length  word_count  \\\n",
       "0  text rush organise transport effort implicatio...          194          32   \n",
       "1  asia vistara surprise swift immaculate steward...          608         109   \n",
       "3                       ever bore carry duty inbound          204          30   \n",
       "4  deserves last block respond mail operator harr...          464          87   \n",
       "5  penalty fail earth would dare season arrogant ...          240          38   \n",
       "\n",
       "   unique_word_count  word_density  uppercase_words  comma_count  \\\n",
       "0                 29      5.878788                0            1   \n",
       "1                 74      5.527273                3            7   \n",
       "3                 30      6.580645                0            2   \n",
       "4                 64      5.272727                4            2   \n",
       "5                 35      6.153846                1            1   \n",
       "\n",
       "   exclamation_count  question_mark_count  avg_sentence_length  \\\n",
       "0                  0                    0             6.600000   \n",
       "1                  0                    0            27.250000   \n",
       "3                  0                    0            10.000000   \n",
       "4                  0                    0            14.833333   \n",
       "5                  0                    1            12.666667   \n",
       "\n",
       "   flesch_reading_score  gunning_fog_index  \n",
       "0                 81.90               5.06  \n",
       "1                 61.19              14.08  \n",
       "3                 61.33               8.00  \n",
       "4                 74.39               7.45  \n",
       "5                 58.58              10.34  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DataScraping_and_processing/karthik_cleaned_data.csv\", index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69468b56-d349-4a8f-b215-b73a5ceab608",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall_rating            0\n",
       "review_date               0\n",
       "review_text               0\n",
       "airline_name              0\n",
       "NPS_category              0\n",
       "NPS                       0\n",
       "language_info             0\n",
       "clean_text              719\n",
       "text_length               0\n",
       "word_count                0\n",
       "unique_word_count         0\n",
       "word_density              0\n",
       "uppercase_words           0\n",
       "comma_count               0\n",
       "exclamation_count         0\n",
       "question_mark_count       0\n",
       "avg_sentence_length       0\n",
       "flesch_reading_score      0\n",
       "gunning_fog_index         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "549c0dc8-17f2-46fb-b6d4-d3bd7fd11b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51d27916-cdcd-4443-8e77-8eb5512257eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Detractor       0.90      0.98      0.94     11894\n",
      "     Neutral       0.07      0.01      0.01       338\n",
      "    Promoter       0.78      0.47      0.58      1920\n",
      "\n",
      "    accuracy                           0.89     14152\n",
      "   macro avg       0.58      0.48      0.51     14152\n",
      "weighted avg       0.86      0.89      0.87     14152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating bag of words representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "bow_matrix = count_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(\n",
    "    bow_matrix, df[\"NPS_category\"], test_size=0.25, random_state=42)\n",
    "\n",
    "clf_bow = MultinomialNB()\n",
    "clf_bow.fit(X_train_bow, y_train_bow)\n",
    "y_pred_bow = clf_bow.predict(X_test_bow)\n",
    "print(\"BoW Classification Report:\\n\", classification_report(y_test_bow, y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "029a94be-101a-4235-9d84-f9826e3867a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Detractor       0.85      1.00      0.92     11894\n",
      "     Neutral       0.00      0.00      0.00       338\n",
      "    Promoter       0.91      0.08      0.14      1920\n",
      "\n",
      "    accuracy                           0.85     14152\n",
      "   macro avg       0.59      0.36      0.35     14152\n",
      "weighted avg       0.84      0.85      0.79     14152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/daaa/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/daaa/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# creating a TF-IDF text representation\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    tfidf_matrix, df[\"NPS_category\"], test_size=0.25, random_state=42)\n",
    "\n",
    "clf_tfidf = MultinomialNB()\n",
    "clf_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Classification Report:\\n\", classification_report(y_test_tfidf, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6319bed9-1b0c-4101-9b5a-56f896274307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Detractor       0.96      1.00      0.98     11894\n",
      "     Neutral       1.00      0.12      0.22       338\n",
      "    Promoter       0.98      0.88      0.93      1920\n",
      "\n",
      "    accuracy                           0.96     14152\n",
      "   macro avg       0.98      0.67      0.71     14152\n",
      "weighted avg       0.96      0.96      0.95     14152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['NPS_category'], test_size=0.25, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "class_idfs = []\n",
    "unique_classes = np.unique(y_train)\n",
    "for class_idx in unique_classes:\n",
    "    class_mask = (y_train == class_idx)\n",
    "    class_docs = X_train[class_mask]\n",
    "    class_vectorizer = TfidfVectorizer(vocabulary=tfidf_vectorizer.vocabulary_)\n",
    "    class_tfidf = class_vectorizer.fit_transform(class_docs)\n",
    "    class_idf = class_vectorizer.idf_\n",
    "    class_idfs.append(class_idf)\n",
    "\n",
    "mean_idf = np.mean(class_idfs, axis=0)\n",
    "\n",
    "delta_idfs = [class_idf - mean_idf for class_idf in class_idfs]\n",
    "\n",
    "class_to_index = {label: index for index, label in enumerate(unique_classes)}\n",
    "\n",
    "X_train_delta_tfidf = []\n",
    "for i, doc in enumerate(X_train_tfidf):\n",
    "    class_idx = class_to_index[y_train.iloc[i]]\n",
    "    delta_idf = delta_idfs[class_idx]\n",
    "    X_train_delta_tfidf.append(doc.multiply(delta_idf))\n",
    "\n",
    "X_train_delta_tfidf = vstack(X_train_delta_tfidf)\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "X_test_delta_tfidf = []\n",
    "for i, doc in enumerate(X_test_tfidf):\n",
    "    class_idx = class_to_index[y_test.iloc[i]]\n",
    "    delta_idf = delta_idfs[class_idx]\n",
    "    X_test_delta_tfidf.append(doc.multiply(delta_idf))\n",
    "\n",
    "X_test_delta_tfidf = vstack(X_test_delta_tfidf)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_delta_tfidf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_delta_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54feef4a-ed17-4953-90a1-89d47aff90a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ccad6-eac8-47e2-95dc-0a0a02d81403",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
