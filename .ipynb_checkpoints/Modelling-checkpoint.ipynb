{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335174c0-ed5d-46ee-8285-184703590a00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfda5fe-a38e-486f-bf34-893fe118d424",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c96760f-b68e-401e-a2a6-d69c9e90ae53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "802cd335-d59d-4c25-bf08-eee02baee785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>airline_name</th>\n",
       "      <th>NPS_category</th>\n",
       "      <th>NPS</th>\n",
       "      <th>language_info</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>uppercase_words</th>\n",
       "      <th>comma_count</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_mark_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>flesch_reading_score</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>2023-09-18 03:29:15</td>\n",
       "      <td>EasyJet sent text at 4.00 am day of flight hom...</td>\n",
       "      <td>easyjet</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>text rush organise transport effort implicatio...</td>\n",
       "      <td>194</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>5.878788</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>81.90</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2023-12-01 00:00:00</td>\n",
       "      <td>Its been a few years when I flew a lot in A...</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>asia vistara surprise swift immaculate steward...</td>\n",
       "      <td>608</td>\n",
       "      <td>109</td>\n",
       "      <td>74</td>\n",
       "      <td>5.527273</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>61.19</td>\n",
       "      <td>14.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>2018-09-09 20:37:11</td>\n",
       "      <td>one of the worst experiences with Air France e...</td>\n",
       "      <td>air france</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>ever bore carry duty inbound</td>\n",
       "      <td>204</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>6.580645</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>61.33</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>2019-12-23 14:00:19</td>\n",
       "      <td>Not a single star this airlines deserves .I lo...</td>\n",
       "      <td>egyptair</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>deserves last block respond mail operator harr...</td>\n",
       "      <td>464</td>\n",
       "      <td>87</td>\n",
       "      <td>64</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>74.39</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>2023-12-29 06:42:56</td>\n",
       "      <td>I was forced to pay 150-euro worth penalty for...</td>\n",
       "      <td>ryanair</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>-1</td>\n",
       "      <td>en</td>\n",
       "      <td>penalty fail earth would dare season arrogant ...</td>\n",
       "      <td>240</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>58.58</td>\n",
       "      <td>10.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           overall_rating          review_date  \\\n",
       "0  Rated 1 out of 5 stars  2023-09-18 03:29:15   \n",
       "1                       9  2023-12-01 00:00:00   \n",
       "3  Rated 1 out of 5 stars  2018-09-09 20:37:11   \n",
       "4  Rated 1 out of 5 stars  2019-12-23 14:00:19   \n",
       "5  Rated 1 out of 5 stars  2023-12-29 06:42:56   \n",
       "\n",
       "                                         review_text airline_name  \\\n",
       "0  EasyJet sent text at 4.00 am day of flight hom...      easyjet   \n",
       "1     Its been a few years when I flew a lot in A...      Vistara   \n",
       "3  one of the worst experiences with Air France e...   air france   \n",
       "4  Not a single star this airlines deserves .I lo...     egyptair   \n",
       "5  I was forced to pay 150-euro worth penalty for...      ryanair   \n",
       "\n",
       "  NPS_category  NPS language_info  \\\n",
       "0    Detractor   -1            en   \n",
       "1     Promoter    1            en   \n",
       "3    Detractor   -1            en   \n",
       "4    Detractor   -1            en   \n",
       "5    Detractor   -1            en   \n",
       "\n",
       "                                          clean_text  text_length  word_count  \\\n",
       "0  text rush organise transport effort implicatio...          194          32   \n",
       "1  asia vistara surprise swift immaculate steward...          608         109   \n",
       "3                       ever bore carry duty inbound          204          30   \n",
       "4  deserves last block respond mail operator harr...          464          87   \n",
       "5  penalty fail earth would dare season arrogant ...          240          38   \n",
       "\n",
       "   unique_word_count  word_density  uppercase_words  comma_count  \\\n",
       "0                 29      5.878788                0            1   \n",
       "1                 74      5.527273                3            7   \n",
       "3                 30      6.580645                0            2   \n",
       "4                 64      5.272727                4            2   \n",
       "5                 35      6.153846                1            1   \n",
       "\n",
       "   exclamation_count  question_mark_count  avg_sentence_length  \\\n",
       "0                  0                    0             6.600000   \n",
       "1                  0                    0            27.250000   \n",
       "3                  0                    0            10.000000   \n",
       "4                  0                    0            14.833333   \n",
       "5                  0                    1            12.666667   \n",
       "\n",
       "   flesch_reading_score  gunning_fog_index  \n",
       "0                 81.90               5.06  \n",
       "1                 61.19              14.08  \n",
       "3                 61.33               8.00  \n",
       "4                 74.39               7.45  \n",
       "5                 58.58              10.34  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DataScraping_and_processing/karthik_cleaned_data.csv\", index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69468b56-d349-4a8f-b215-b73a5ceab608",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall_rating            0\n",
       "review_date               0\n",
       "review_text               0\n",
       "airline_name              0\n",
       "NPS_category              0\n",
       "NPS                       0\n",
       "language_info             0\n",
       "clean_text              719\n",
       "text_length               0\n",
       "word_count                0\n",
       "unique_word_count         0\n",
       "word_density              0\n",
       "uppercase_words           0\n",
       "comma_count               0\n",
       "exclamation_count         0\n",
       "question_mark_count       0\n",
       "avg_sentence_length       0\n",
       "flesch_reading_score      0\n",
       "gunning_fog_index         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549c0dc8-17f2-46fb-b6d4-d3bd7fd11b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d27916-cdcd-4443-8e77-8eb5512257eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Detractor       0.90      0.98      0.94     11894\n",
      "     Neutral       0.07      0.01      0.01       338\n",
      "    Promoter       0.78      0.47      0.58      1920\n",
      "\n",
      "    accuracy                           0.89     14152\n",
      "   macro avg       0.58      0.48      0.51     14152\n",
      "weighted avg       0.86      0.89      0.87     14152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating bag of words representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "bow_matrix = count_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(\n",
    "    bow_matrix, df[\"NPS_category\"], test_size=0.25, random_state=42)\n",
    "\n",
    "clf_bow = MultinomialNB()\n",
    "clf_bow.fit(X_train_bow, y_train_bow)\n",
    "y_pred_bow = clf_bow.predict(X_test_bow)\n",
    "print(\"BoW Classification Report:\\n\", classification_report(y_test_bow, y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029a94be-101a-4235-9d84-f9826e3867a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Detractor       0.85      1.00      0.92     11894\n",
      "     Neutral       0.00      0.00      0.00       338\n",
      "    Promoter       0.91      0.08      0.14      1920\n",
      "\n",
      "    accuracy                           0.85     14152\n",
      "   macro avg       0.59      0.36      0.35     14152\n",
      "weighted avg       0.84      0.85      0.79     14152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/daaa/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/daaa/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# creating a TF-IDF text representation\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    tfidf_matrix, df[\"NPS_category\"], test_size=0.25, random_state=42)\n",
    "\n",
    "clf_tfidf = MultinomialNB()\n",
    "clf_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Classification Report:\\n\", classification_report(y_test_tfidf, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6319bed9-1b0c-4101-9b5a-56f896274307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daaa/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Detractor       0.96      1.00      0.98     11894\n",
      "     Neutral       1.00      0.12      0.22       338\n",
      "    Promoter       0.98      0.88      0.93      1920\n",
      "\n",
      "    accuracy                           0.96     14152\n",
      "   macro avg       0.98      0.67      0.71     14152\n",
      "weighted avg       0.96      0.96      0.95     14152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['NPS_category'], test_size=0.25, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "class_idfs = []\n",
    "unique_classes = np.unique(y_train)\n",
    "for class_idx in unique_classes:\n",
    "    class_mask = (y_train == class_idx)\n",
    "    class_docs = X_train[class_mask]\n",
    "    class_vectorizer = TfidfVectorizer(vocabulary=tfidf_vectorizer.vocabulary_)\n",
    "    class_tfidf = class_vectorizer.fit_transform(class_docs)\n",
    "    class_idf = class_vectorizer.idf_\n",
    "    class_idfs.append(class_idf)\n",
    "\n",
    "mean_idf = np.mean(class_idfs, axis=0)\n",
    "\n",
    "delta_idfs = [class_idf - mean_idf for class_idf in class_idfs]\n",
    "\n",
    "class_to_index = {label: index for index, label in enumerate(unique_classes)}\n",
    "\n",
    "X_train_delta_tfidf = []\n",
    "for i, doc in enumerate(X_train_tfidf):\n",
    "    class_idx = class_to_index[y_train.iloc[i]]\n",
    "    delta_idf = delta_idfs[class_idx]\n",
    "    X_train_delta_tfidf.append(doc.multiply(delta_idf))\n",
    "\n",
    "X_train_delta_tfidf = vstack(X_train_delta_tfidf)\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "X_test_delta_tfidf = []\n",
    "for i, doc in enumerate(X_test_tfidf):\n",
    "    class_idx = class_to_index[y_test.iloc[i]]\n",
    "    delta_idf = delta_idfs[class_idx]\n",
    "    X_test_delta_tfidf.append(doc.multiply(delta_idf))\n",
    "\n",
    "X_test_delta_tfidf = vstack(X_test_delta_tfidf)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_delta_tfidf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_delta_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f6d2a-8e60-4af2-8c65-6bc465f6a7e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data balancing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdf38496-7987-47ac-9de7-fb790dd0309a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to ComplementNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m clf_bow_res \u001b[38;5;241m=\u001b[39m ComplementNB()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Fit the classifier on the resampled training data\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mclf_bow_res\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_delta_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Predict on the test set using the trained pipeline\u001b[39;00m\n\u001b[1;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf_bow_res\u001b[38;5;241m.\u001b[39mpredict(X_test_delta_tfidf)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/naive_bayes.py:772\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    770\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[0;32m--> 772\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/naive_bayes.py:1040\u001b[0m, in \u001b[0;36mComplementNB._count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count feature occurrences.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComplementNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/utils/validation.py:1490\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to ComplementNB (input X)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the clean_text to create BoW representation\n",
    "bow_matrix = count_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(\n",
    "    bow_matrix, df[\"NPS_category\"], test_size=0.25, random_state=42, stratify=df[\"NPS_category\"])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "\n",
    "# Initialize the classifier\n",
    "clf_bow_res = ComplementNB()\n",
    "\n",
    "# Fit the classifier on the resampled training data\n",
    "clf_bow_res.fit(X_train_delta_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set using the trained pipeline\n",
    "y_pred = clf_bow_res.predict(X_test_delta_tfidf)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f726b11f-fc0c-4d17-b5e7-ee9c4ee600df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after Random OverSampling: Counter({'Detractor': 35651, 'Promoter': 35651, 'Neutral': 35651})\n",
      "BoW Classification Report after Random OverSampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Detractor       0.95      0.89      0.91     11894\n",
      "     Neutral       0.09      0.33      0.14       338\n",
      "    Promoter       0.65      0.61      0.63      1920\n",
      "\n",
      "    accuracy                           0.84     14152\n",
      "   macro avg       0.56      0.61      0.56     14152\n",
      "weighted avg       0.89      0.84      0.86     14152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming df[\"clean_text\"] and df[\"NPS_category\"] are already defined\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the clean_text to create BoW representation\n",
    "bow_matrix = count_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(\n",
    "    bow_matrix, df[\"NPS_category\"], test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Apply RandomOverSampler to training data only\n",
    "X_train_bow_res, y_train_bow_res = ros.fit_resample(X_train_bow, y_train_bow)\n",
    "\n",
    "# Check the class distribution after resampling\n",
    "print(\"Class distribution after Random OverSampling:\", Counter(y_train_bow_res))\n",
    "\n",
    "# Initialize the classifier\n",
    "clf_bow_res = ComplementNB()\n",
    "\n",
    "# Fit the classifier on the resampled training data\n",
    "clf_bow_res.fit(X_train_bow_res, y_train_bow_res)\n",
    "\n",
    "# Predict on the original (non-resampled) testing data\n",
    "y_pred_bow_res = clf_bow_res.predict(X_test_bow)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"BoW Classification Report after Random OverSampling:\\n\", classification_report(y_test_bow, y_pred_bow_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b1ccf2-9c32-4700-877d-e97697d4285b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Classification Report after SMOTE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Detractor       0.93      0.93      0.93     11894\n",
      "     Neutral       0.08      0.16      0.11       338\n",
      "    Promoter       0.68      0.61      0.64      1920\n",
      "\n",
      "    accuracy                           0.86     14152\n",
      "   macro avg       0.57      0.56      0.56     14152\n",
      "weighted avg       0.88      0.86      0.87     14152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming df[\"clean_text\"] and df[\"NPS_category\"] are already defined\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the clean_text to create BoW representation\n",
    "bow_matrix = count_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(\n",
    "    bow_matrix, df[\"NPS_category\"], test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data only\n",
    "X_train_bow_smote, y_train_bow_smote = smote.fit_resample(X_train_bow, y_train_bow)\n",
    "\n",
    "# Initialize the classifier\n",
    "clf_bow_smote = ComplementNB()\n",
    "\n",
    "# Fit the classifier on the resampled training data\n",
    "clf_bow_smote.fit(X_train_bow_smote, y_train_bow_smote)\n",
    "\n",
    "# Predict on the original (non-resampled) testing data\n",
    "y_pred_bow_smote = clf_bow_smote.predict(X_test_bow)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"BoW Classification Report after SMOTE:\\n\", classification_report(y_test_bow, y_pred_bow_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aa51c62-bffa-4c3a-9b3e-8a54dea1b675",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Classification Report after ADASYN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Detractor       0.93      0.92      0.93     11894\n",
      "     Neutral       0.08      0.16      0.10       338\n",
      "    Promoter       0.66      0.61      0.64      1920\n",
      "\n",
      "    accuracy                           0.86     14152\n",
      "   macro avg       0.56      0.56      0.56     14152\n",
      "weighted avg       0.88      0.86      0.87     14152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming df[\"clean_text\"] and df[\"NPS_category\"] are already defined\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the clean_text to create BoW representation\n",
    "bow_matrix = count_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(\n",
    "    bow_matrix, df[\"NPS_category\"], test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize ADASYN\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "# Apply ADASYN to training data only\n",
    "X_train_bow_adasyn, y_train_bow_adasyn = adasyn.fit_resample(X_train_bow, y_train_bow)\n",
    "\n",
    "# Initialize the classifier\n",
    "clf_bow_adasyn = ComplementNB()\n",
    "\n",
    "# Fit the classifier on the resampled training data\n",
    "clf_bow_adasyn.fit(X_train_bow_adasyn, y_train_bow_adasyn)\n",
    "\n",
    "# Predict on the original (non-resampled) testing data\n",
    "y_pred_bow_adasyn = clf_bow_adasyn.predict(X_test_bow)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"BoW Classification Report after ADASYN:\\n\", classification_report(y_test_bow, y_pred_bow_adasyn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54feef4a-ed17-4953-90a1-89d47aff90a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ccad6-eac8-47e2-95dc-0a0a02d81403",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
