{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43dd500-b937-46ca-96a4-798419df30aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Installing and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6bb90a8-7dd0-4c2d-a100-8a60deeef3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install Unidecode\n",
    "# %pip install selenium-stealth\n",
    "# %pip install undetected-chromedriver\n",
    "# %pip install webdriver-manager\n",
    "# %pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb808513-7026-4ec8-9325-2092d727ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium_stealth import stealth\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "import pickle\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium_stealth import stealth\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbbf8ce-968d-4666-8683-25284c72578d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Setting up webdrivers\n",
    "- configures the driver to ignore SSL certificate errors\n",
    "- open pages in incognito mode\n",
    "- operate in headless mode (without opening a browser window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7954b169-7c86-407e-b796-09722a4b658f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_webdriver():\n",
    "    print(\"Starting to initialize webdriver...\")\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--incognito')\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    print(\"Webdriver initialized.\")\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942c267-6a66-4232-9d72-efc8efd20b96",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Scraping Links to Airline Review from Tripadvisor\n",
    "\n",
    "*Note: \n",
    "In scraping airline review links, I initially targeted TripAdvisor but encountered robust security barriers like IP rate limiting, captchas, and bot detection. Despite efforts using proxies, rotating user agents, and advanced scraping tools, bypassing these measures proved unsuccessful. Consequently, I pivoted to TrustPilot. While TrustPilot's content is more diverse, making specific airline review scraping less straightforward, I utilized a pre-collected list of airline names from TripAdvisor to efficiently extract review links from TrustPilot.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66e03a87-92e2-4fe9-9fe1-b40a0b94158b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_page(driver, csv_writer):\n",
    "    try:\n",
    "        airlines = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".prw_rup.prw_airlines_airline_lander_card\"))\n",
    "        )\n",
    "        for airline in airlines:\n",
    "            name = airline.find_element(By.CSS_SELECTOR, \".airlineName\").text\n",
    "            review_link_element = airline.find_element(By.CSS_SELECTOR, \"a.review_button.ui_button.secondary.small\")\n",
    "            review_link = review_link_element.get_attribute(\"href\")\n",
    "            num_reviews = airline.find_element(By.CSS_SELECTOR, \".airlineReviews\").text\n",
    "            csv_writer.writerow([name, review_link, num_reviews])\n",
    "\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"Error occurred while scraping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4024f773-dfe0-41ea-9ee1-e6b41d5bb338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main1():\n",
    "    driver = initialize_webdriver()\n",
    "    driver.get(\"https://www.tripadvisor.com/Airlines\")\n",
    "    \n",
    "    with open('scraped_data.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['Airline Name', 'Review Link', 'Number of Reviews'])\n",
    "\n",
    "        page_number = 1\n",
    "        while True:\n",
    "            print(f\"Scraping page {page_number}...\")\n",
    "            scrape_page(driver, csv_writer)\n",
    "\n",
    "            try:\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \"span.nav.next.ui_button.primary\"))\n",
    "                )\n",
    "                if \"disabled\" in next_button.get_attribute(\"class\"):\n",
    "                    print(\"Reached the last page.\")\n",
    "                    break\n",
    "\n",
    "                next_button.click()\n",
    "                WebDriverWait(driver, 10).until(EC.staleness_of(next_button))\n",
    "                page_number += 1\n",
    "                time.sleep(1)\n",
    "\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                print(\"Reached the end of the pages or encountered an error.\")\n",
    "                break\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c002e5f2-c023-49ca-becc-33e609d2e08c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Error occurred while scraping.\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Error occurred while scraping.\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Error occurred while scraping.\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Error occurred while scraping.\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Scraping page 36...\n",
      "Scraping page 37...\n",
      "Scraping page 38...\n",
      "Scraping page 39...\n",
      "Scraping page 40...\n",
      "Error occurred while scraping.\n",
      "Scraping page 41...\n",
      "Scraping page 42...\n",
      "Error occurred while scraping.\n",
      "Scraping page 43...\n",
      "Scraping page 44...\n",
      "Scraping page 45...\n",
      "Scraping page 46...\n",
      "Scraping page 47...\n",
      "Scraping page 48...\n",
      "Scraping page 49...\n",
      "Scraping page 50...\n",
      "Scraping page 51...\n",
      "Scraping page 52...\n",
      "Scraping page 53...\n",
      "Scraping page 54...\n",
      "Scraping page 55...\n",
      "Scraping page 56...\n",
      "Scraping page 57...\n",
      "Scraping page 58...\n",
      "Scraping page 59...\n",
      "Scraping page 60...\n",
      "Scraping page 61...\n",
      "Scraping page 62...\n",
      "Scraping page 63...\n",
      "Reached the last page.\n"
     ]
    }
   ],
   "source": [
    "main1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29a5b4-d76a-469a-b8d2-4523f0a5cdd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### ⚠️ Deprecated TripAdvisor Review Scraping Approach (Switched to TrustPilot)\n",
    "\n",
    "Despite extensive efforts to navigate TripAdvisor's security, including user agent rotation, utilizing a variety of proxies (though limited by the efficacy of free proxies), VPN for changing servers, and manual captcha resolution, the attempts faced significant roadblocks. The site's security measures effectively limited scraping activities to merely 3-4 page accesses (driver.get() operations) before necessitating an IP change via VPN. This made it very challenging to get a lot of data especially because each page only contained 5 reviews. Manual captcha interventions were of no use as after solving the captcha i would immediately get blocked. Moreover, any progress made by scraping an initial page of reviews was quickly stopped by the bot detection from accessing subsequent pages. Using tools like selenium stealth and undetected chrome agent also proved to be inaffective.\n",
    "\n",
    "One solution could have been to buy a list of paid proxies and rotate through these every time tripadvisor blocks us from the page however these proxies are quite expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4259e0d-92c7-4929-9ffb-00dfbc2e2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_webdriver():\n",
    "    print(\"started to init\")\n",
    "    options = webdriver.ChromeOptions()\n",
    "    ua = UserAgent()\n",
    "    my_user_agent = ua.chrome\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--incognito')\n",
    "    options.add_argument('--start-maximized')\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--disable-popup-blocking')\n",
    "    options.add_argument('--profile-directory=Default')\n",
    "    options.add_argument('--disable-plugins-discovery')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    driver = webdriver.Chrome(service = Service(ChromeDriverManager().install()), options=options)\n",
    "    print(\"init complete\")\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19779e1c-3787-47bb-8e74-1aac8ed677db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_read_more(driver):\n",
    "    read_more_buttons = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_all_elements_located(\n",
    "            (By.CSS_SELECTOR, \"div.lszDU div.TnInx[data-test-target='expand-review']\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for button in read_more_buttons:\n",
    "        try:\n",
    "            button.click()\n",
    "            time.sleep(4)\n",
    "            print(\"button clicked !!!\")\n",
    "            WebDriverWait(driver, 10).until(EC.staleness_of(button))\n",
    "        except Exception as e:\n",
    "            print(\"Warning: Button Click Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66bf0c-5558-48de-81c8-412d35caa389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mouse_movement(driver):\n",
    "    action = ActionChains(driver)\n",
    "    action.move_by_offset(random.randint(0, 100), random.randint(0, 100))\n",
    "    action.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc8f5d-e111-4470-886d-91a0c17405c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_webpage(driver, url):\n",
    "    print(\"started scraping\")\n",
    "    driver.get(url)\n",
    "    all_reviews = []\n",
    "    output_file = 'scraped_airline_reviews.csv'\n",
    "    \n",
    "    while True:\n",
    "        click_read_more(driver)\n",
    "        time.sleep(10)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"lgfjP.Gi.z.pBVnE.MD.bZHZM\")))\n",
    "        elements = driver.find_elements(By.CLASS_NAME, \"lgfjP.Gi.z.pBVnE.MD.bZHZM\")\n",
    "        elements_html = [element.get_attribute('outerHTML') for element in elements]\n",
    "\n",
    "        all_reviews.extend([parse_review(html, url) for html in elements_html if html is not None])\n",
    "        save_reviews_to_csv(all_reviews, output_file)\n",
    "        \n",
    "        try:\n",
    "            next_button = driver.find_element(By.CLASS_NAME, \"nav.next.primary\")\n",
    "            if 'disabled' in next_button.get_attribute('class'):\n",
    "                break  # If the Next button is disabled, exit the loop\n",
    "            next_button.click()\n",
    "            WebDriverWait(driver, 10).until(EC.staleness_of(next_button))\n",
    "            print(\"Navigated to next page\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"No more pages found.\")\n",
    "            break\n",
    "            \n",
    "        random_mouse_movement(driver)\n",
    "        random_sleep(2, 5)\n",
    "\n",
    "    print(\"scraping done\")\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0443ea-a6b3-4a00-bcb6-a6e8cbbed732",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_reviews = set()\n",
    "\n",
    "def parse_review(html, url):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    review_data = {}\n",
    "    output_file = 'scraped_airline_reviews.csv'\n",
    "    \n",
    "    review_data['airline_url'] = url\n",
    "    user_info = soup.find('a', class_='ui_header_link')\n",
    "    if user_info:\n",
    "        user_name = user_info.get_text(strip=True)\n",
    "        review_date_div = soup.find('div', class_='cRVSd')\n",
    "        if review_date_div:\n",
    "            review_date = review_date_div.get_text()\n",
    "            unique_id = (url, user_name, review_date)\n",
    "            if unique_id in existing_reviews:\n",
    "                return None\n",
    "            existing_reviews.add(unique_id)\n",
    "            review_data['user_name'] = user_name\n",
    "            review_data['review_date'] = review_date\n",
    "            review_data['scraped_date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    travel_details = soup.find_all('div', class_='dmRSR n R2 S2')\n",
    "    review_data['travel_details'] = [detail.get_text(strip=True) for detail in travel_details]\n",
    "\n",
    "    review_title = soup.find('div', class_='KgQgP MC _S b S6 H5 _a')\n",
    "    review_data['review_title'] = review_title.get_text(strip=True) if review_title else None\n",
    "    review_text = soup.find('span', class_='QewHA H4 _a')\n",
    "    review_data['review_text'] = review_text.get_text(strip=True) if review_text else None\n",
    "    \n",
    "    overall_rating = soup.find('span', class_='ui_bubble_rating')\n",
    "    review_data['overall_rating'] = int(overall_rating['class'][1].split('_')[-1]) // 10 if overall_rating else None\n",
    "\n",
    "    subratings = soup.find_all('div', class_='hemdC S2 H2')\n",
    "    review_data['subratings'] = {}\n",
    "    for subrating in subratings:\n",
    "        category = subrating.get_text(strip=True)\n",
    "        rating_class = subrating.find('span', class_='ui_bubble_rating')['class'][1]\n",
    "        review_data['subratings'][category] = int(rating_class.split('_')[-1]) // 10\n",
    "        \n",
    "    return review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90faea6-ff68-4cc7-a266-d72558c27ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reviews_to_csv(reviews, file_path):\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    \n",
    "    with open(file_path, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=reviews[0].keys())\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writeheader() \n",
    "        \n",
    "        for review in reviews:\n",
    "            writer.writerow(review)\n",
    "            \n",
    "def check_for_captcha(driver):\n",
    "    try:\n",
    "        captcha_iframe = driver.find_element(By.TAG_NAME, \"iframe\")\n",
    "        if \"captcha\" in captcha_iframe.get_attribute(\"src\"):\n",
    "            return True\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "\n",
    "def create_batches(df, batch_size):\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        yield df[i:i + batch_size]\n",
    "\n",
    "def read_processed_links(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            return set(line.strip() for line in file)\n",
    "    return set()\n",
    "\n",
    "def add_processed_link(file_path, link):\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(link + '\\n')\n",
    "        \n",
    "def save_reviews_to_csv(reviews, file_path):\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    \n",
    "    with open(file_path, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=reviews[0].keys())\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writeheader() \n",
    "        \n",
    "        for review in reviews:\n",
    "            writer.writerow(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ac2f2-df74-40e9-9c8f-c23338a114f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_button(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.CLASS_NAME, \"nav.next.primary\")\n",
    "    except NoSuchElementException:\n",
    "        return None\n",
    "\n",
    "def random_sleep(min_sec, max_sec):\n",
    "    time.sleep(random.uniform(min_sec, max_sec))\n",
    "\n",
    "def main():\n",
    "    meta_df = pd.read_csv(\"./scraped_data.csv\")\n",
    "    batch_size = 1\n",
    "    processed_links_file = 'processed_links.txt'\n",
    "    processed_links = read_processed_links(processed_links_file)\n",
    "    output_file = 'scraped_airline_reviews.csv'\n",
    "\n",
    "    driver = initialize_webdriver()\n",
    "    stealth(driver,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "            fix_hairline=True,\n",
    "    )\n",
    "\n",
    "    for batch in create_batches(meta_df, batch_size):\n",
    "        for review_link in batch['Review Link']:\n",
    "            if review_link in processed_links:\n",
    "                print(f\"Skipping already processed link: {review_link}\")\n",
    "                continue\n",
    "\n",
    "            print(f'Starting to scrape: {review_link}')\n",
    "            random_sleep(15, 20) \n",
    "\n",
    "            driver.get(review_link)\n",
    "            while True:\n",
    "                if check_for_captcha(driver):\n",
    "                    input(\"CAPTCHA detected. Please solve it and then press Enter to continue...\")\n",
    "                    time.sleep(5)\n",
    "\n",
    "                elements_html = scrape_webpage(driver, review_link)\n",
    "                all_reviews = [review for review in (parse_review(html, review_link) for html in elements_html) if review and (review.get('review_text') or review.get('overall_rating'))]\n",
    "\n",
    "                if all_reviews:\n",
    "                    save_reviews_to_csv(all_reviews, output_file)\n",
    "\n",
    "                next_button = get_next_button(driver)\n",
    "                if next_button and 'disabled' not in next_button.get_attribute('class'):\n",
    "                    href = next_button.get_attribute('href')\n",
    "                    print(f\"Navigating to: {href}\")\n",
    "                    next_button.click()\n",
    "                    random_sleep(5, 10)\n",
    "                else:\n",
    "                    print(\"No more pages to navigate or Next button is disabled.\")\n",
    "                    break\n",
    "\n",
    "            add_processed_link(processed_links_file, review_link)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2075a212-c6ad-44a6-86fd-6994355f9c4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Collecting the links to each airline reviews from trustpilot\n",
    "\n",
    "- The code defines a function to search for and collect links from Trustpilot based on airline names from a CSV file which was obtained by scraping tripadvisor.\n",
    "- It skips queries already processed which is kept track of using a set.\n",
    "- Selenium is used to interact with the website and extract the links\n",
    "- Levenshtein distance checks for close matches between query and result titles.\n",
    "- Found links are appended to a CSV, maintaining a record of processed queries.\n",
    "- A cleaning function is used to standardize text for better matching.\n",
    "- The main part reads an airline dataset, initializes the WebDriver, identifies the last processed query, and runs the link-finding function for unprocessed queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0cbf06e-b969-4777-a0de-d64d7a6907c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline Name</th>\n",
       "      <th>Review Link</th>\n",
       "      <th>Number of Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adria Airways [no longer operating]</td>\n",
       "      <td>https://www.tripadvisor.com/Airline_Review-d87...</td>\n",
       "      <td>670 reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Air</td>\n",
       "      <td>https://www.tripadvisor.com/Airline_Review-d17...</td>\n",
       "      <td>18 reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEGEAN</td>\n",
       "      <td>https://www.tripadvisor.com/Airline_Review-d87...</td>\n",
       "      <td>13,439 reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aer Lingus</td>\n",
       "      <td>https://www.tripadvisor.com/Airline_Review-d87...</td>\n",
       "      <td>13,330 reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aero Mongolia</td>\n",
       "      <td>https://www.tripadvisor.com/Airline_Review-d13...</td>\n",
       "      <td>18 reviews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Airline Name  \\\n",
       "0  Adria Airways [no longer operating]   \n",
       "1                         Advanced Air   \n",
       "2                               AEGEAN   \n",
       "3                           Aer Lingus   \n",
       "4                        Aero Mongolia   \n",
       "\n",
       "                                         Review Link Number of Reviews  \n",
       "0  https://www.tripadvisor.com/Airline_Review-d87...       670 reviews  \n",
       "1  https://www.tripadvisor.com/Airline_Review-d17...        18 reviews  \n",
       "2  https://www.tripadvisor.com/Airline_Review-d87...    13,439 reviews  \n",
       "3  https://www.tripadvisor.com/Airline_Review-d87...    13,330 reviews  \n",
       "4  https://www.tripadvisor.com/Airline_Review-d13...        18 reviews  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.read_csv(\"./karthik_datasets/scraped_data.csv\")\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7790504c-a258-408d-913b-0a85ef6dd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_links_for_query(driver, query, csv_file, processed_queries, start_index=0):\n",
    "    for i, query in enumerate(df[\"Airline Name\"][start_index:], start=start_index):\n",
    "        if query in processed_queries:\n",
    "            print(f\"Skipping query: {query} (already processed)\")\n",
    "            continue\n",
    "\n",
    "        driver.get(\"https://www.trustpilot.com/search?query=s\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        search_input = driver.find_element(By.CLASS_NAME, 'search-desktop_searchInputField__CHV3l')\n",
    "        search_input.clear()\n",
    "        search_input.send_keys(query)\n",
    "        search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        elements = driver.find_elements(By.CLASS_NAME, 'paper_paper__1PY90.paper_outline__lwsUX.card_card__lQWDv.card_noPadding__D8PcU.styles_wrapper__2JOo2.styles_businessUnitResult__L3bbC')\n",
    "\n",
    "        for element in elements:\n",
    "            title_element = element.find_element(By.CLASS_NAME, 'typography_heading-xs__jSwUz.typography_appearance-default__AAY17.styles_displayName__GOhL2').text\n",
    "            levenshtein_distance = Levenshtein.distance(clean_text(query), clean_text(title_element))\n",
    "            if levenshtein_distance <= 0.3:\n",
    "                link_element = element.find_element(By.XPATH, './/a[@class=\"link_internal__7XN06 link_wrapper__5ZJEx styles_linkWrapper__UWs5j\"]')\n",
    "                link = link_element.get_attribute(\"href\")\n",
    "                data = {'Query': query, 'Link': link}\n",
    "                pd.DataFrame([data]).to_csv(csv_file, mode='a', header=not os.path.exists(csv_file), index=False)\n",
    "\n",
    "        processed_queries.add(query)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = unidecode.unidecode(text).lower()\n",
    "    cleaned_text = re.sub(r'\\s*[\\(\\[\\{][^\\)\\]\\}]*[\\)\\]\\}]\\s*', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', cleaned_text).strip().lower()\n",
    "\n",
    "\n",
    "existing_data = pd.read_csv('./karthik_datasets/results.csv')\n",
    "processed_queries = set(existing_data['Query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06616e8-4453-445f-8516-14bef53dd279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "Skipping query: yeti airlines (already processed)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('karthik_datasets/scraped_data.csv')\n",
    "df['Airline Name'] = df['Airline Name'].apply(clean_text)\n",
    "\n",
    "driver = initialize_webdriver()\n",
    "\n",
    "last_processed_index = df[df['Airline Name'].isin(processed_queries)].index.max() or 0\n",
    "\n",
    "find_links_for_query(driver, df[\"Airline Name\"], 'results.csv', processed_queries, last_processed_index)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060d214-de53-4dd8-80e0-32b495ed1c8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scraping the airline reviews from trustpilot\n",
    "\n",
    "- navigate_to_reviews_page: Loads a given URL in the browser.\n",
    "- scroll_to_element: Scrolls the browser to make the next button element visible.\n",
    "- get_next_page_href: Checks for a \"next page\" button and returns its link if available; otherwise, returns None.\n",
    "- extract_reviews_data: Collects review details from the current page and stores them in a list.\n",
    "- main: Orchestrates the scraping process for reviews from a given URL, saving the data to a CSV file and navigating through pages until no more are found.\n",
    "- update_status: Updates the status of a link in a DataFrame to track progress.\n",
    "- process_links: Iterates through links in a provided CSV, scraping reviews for each and updating their status, indicating whether data collection was successful or encountered errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ab0d5e-bbfc-4b80-8e58-3b4527878dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def navigate_to_reviews_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c683e71-8e0b-4350-b065-8bba32a8e16c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scroll_to_element(driver, element):\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "\n",
    "def get_next_page_href(driver):\n",
    "    try:\n",
    "        next_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//a[@name='pagination-button-next']\"))\n",
    "        )\n",
    "        if next_button.get_attribute('aria-disabled') == 'true':\n",
    "            return None  # Button is disabled, no more pages\n",
    "        else:\n",
    "            scroll_to_element(driver, next_button)  # Scroll to make the button visible\n",
    "            return next_button.get_attribute('href')  # Return the href attribute\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca61b604-99fd-4ca0-a26f-f689374716ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_reviews_data(driver):\n",
    "    all_reviews = []\n",
    "\n",
    "    review_elements = driver.find_elements(By.CSS_SELECTOR, '.styles_cardWrapper__LcCPA')\n",
    "\n",
    "    for review in review_elements:\n",
    "        single_review = {\n",
    "            'Stars': review.find_element(By.CSS_SELECTOR, '.star-rating_starRating__4rrcf img').get_attribute('alt'),\n",
    "            'Post Title': review.find_element(By.CSS_SELECTOR, '.typography_heading-s__f7029').text,\n",
    "            'Person': review.find_element(By.CSS_SELECTOR, '.typography_heading-xxs__QKBS8').text,\n",
    "            'Date Posted': review.find_element(By.CSS_SELECTOR,'time').get_attribute('title'),\n",
    "            'Date of Experience': review.find_element(By.CSS_SELECTOR, '.typography_body-m__xgxZ_.typography_appearance-default__AAY17').text,\n",
    "            'Review Text': review.find_element(By.CSS_SELECTOR, '.typography_body-l__KUYFJ').text\n",
    "        }\n",
    "        all_reviews.append(single_review)\n",
    "    \n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9aecfce-c837-464b-9e24-db665e6bab56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(url):\n",
    "    driver = initialize_webdriver()\n",
    "    navigate_to_reviews_page(driver, url)\n",
    "    \n",
    "    file_exists = os.path.isfile('reviews.csv')\n",
    "\n",
    "    with open('testing.csv', 'a', newline='', encoding='utf-8') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "\n",
    "        if not file_exists:\n",
    "            csv_writer.writerow(['Stars', 'Post Title', 'Person', 'Date Posted', 'Date of Experience', 'Review Text', 'Link'])\n",
    "\n",
    "        while True:\n",
    "            data = extract_reviews_data(driver)\n",
    "\n",
    "            for review in data:\n",
    "                review['Link'] = url\n",
    "                csv_writer.writerow([review['Stars'], review['Post Title'], review['Person'], review['Date Posted'], review['Date of Experience'], review['Review Text'], review['Link']])\n",
    "\n",
    "            next_page_url = get_next_page_href(driver)\n",
    "            if not next_page_url:\n",
    "                print(review['Link'], \"scraping finished\")\n",
    "                break  \n",
    "\n",
    "            driver.get(next_page_url)\n",
    "            time.sleep(3)\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95dab456-4504-4291-af34-a414855f44d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/www.butaairways.az scraping finished\n"
     ]
    }
   ],
   "source": [
    "test_Url = \"https://www.trustpilot.com/review/www.butaairways.az\"\n",
    "main(test_Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e77b311d-aa51-438d-826e-d8e65f90211b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/m.vueling.com scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/www.westjet.com scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/westjet.ca scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/www.wideroe.no scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/www.wingo.ch scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/wingo.com scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/wingo.store scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/wizzair.uk scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/wizzair.pl scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/wizzair.co.uk scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/wowair.is scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/wowair.com scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/wowair.dk scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/xiamenair.com scraping finished\n",
      "Starting to initialize webdriver...\n",
      "Webdriver initialized.\n",
      "https://www.trustpilot.com/review/www.yetiairlines.com scraping finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Query</th>\n",
       "      <th>Link</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aer lingus</td>\n",
       "      <td>https://www.trustpilot.com/review/www.aerlingu...</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aeroflot</td>\n",
       "      <td>https://www.trustpilot.com/review/aeroflot.com</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>aerolineas argentinas</td>\n",
       "      <td>https://www.trustpilot.com/review/aerolineas.c...</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>aeromexico</td>\n",
       "      <td>https://www.trustpilot.com/review/aeromexico.com</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>aeromexico</td>\n",
       "      <td>https://www.trustpilot.com/review/aeromexico.pro</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>wow air</td>\n",
       "      <td>https://www.trustpilot.com/review/wowair.is</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>335</td>\n",
       "      <td>335</td>\n",
       "      <td>wow air</td>\n",
       "      <td>https://www.trustpilot.com/review/wowair.com</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>336</td>\n",
       "      <td>336</td>\n",
       "      <td>wow air</td>\n",
       "      <td>https://www.trustpilot.com/review/wowair.dk</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>xiamen airlines</td>\n",
       "      <td>https://www.trustpilot.com/review/xiamenair.com</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>338</td>\n",
       "      <td>338</td>\n",
       "      <td>yeti airlines</td>\n",
       "      <td>https://www.trustpilot.com/review/www.yetiairl...</td>\n",
       "      <td>Collected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0                  Query  \\\n",
       "0               0           0             aer lingus   \n",
       "1               1           1               aeroflot   \n",
       "2               2           2  aerolineas argentinas   \n",
       "3               3           3             aeromexico   \n",
       "4               4           4             aeromexico   \n",
       "..            ...         ...                    ...   \n",
       "326           334         334                wow air   \n",
       "327           335         335                wow air   \n",
       "328           336         336                wow air   \n",
       "329           337         337        xiamen airlines   \n",
       "330           338         338          yeti airlines   \n",
       "\n",
       "                                                  Link     Status  \n",
       "0    https://www.trustpilot.com/review/www.aerlingu...  Collected  \n",
       "1       https://www.trustpilot.com/review/aeroflot.com  Collected  \n",
       "2    https://www.trustpilot.com/review/aerolineas.c...  Collected  \n",
       "3     https://www.trustpilot.com/review/aeromexico.com  Collected  \n",
       "4     https://www.trustpilot.com/review/aeromexico.pro  Collected  \n",
       "..                                                 ...        ...  \n",
       "326        https://www.trustpilot.com/review/wowair.is  Collected  \n",
       "327       https://www.trustpilot.com/review/wowair.com  Collected  \n",
       "328        https://www.trustpilot.com/review/wowair.dk  Collected  \n",
       "329    https://www.trustpilot.com/review/xiamenair.com  Collected  \n",
       "330  https://www.trustpilot.com/review/www.yetiairl...  Collected  \n",
       "\n",
       "[331 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_status(df, link, status):\n",
    "    df.loc[df['Link'] == link, 'Status'] = status\n",
    "    return df\n",
    "\n",
    "def process_links(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    if 'Status' not in df.columns:\n",
    "        df['Status'] = 'Not Collected'\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Status'] == 'Collected':\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            main(row['Link'])\n",
    "            df = update_status(df, row['Link'], 'Collected')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row['Link']}: {e}\")\n",
    "            df = update_status(df, row['Link'], 'Error')\n",
    "            continue\n",
    "            \n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "process_links('results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8050528-ad96-40c9-b0bb-541230d6f2b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### merging Airline Name column to the reviews.csv\n",
    "- Merge DataFrames on the 'Link' column, retaining all rows from reviews and only the 'Link' and 'Query' (airline name) columns from results. The merge is done using a left join, meaning all entries from reviews will be kept, even if there's no matching entry in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9a52779-a3d5-474a-a120-3f415c82f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviews.csv\")\n",
    "results = pd.read_csv(\"results.csv\")\n",
    "\n",
    "merged_df = pd.merge(reviews, results[['Link', 'Query']], on='Link', how='left')\n",
    "\n",
    "merged_df.drop('Link', axis=1, inplace=True)\n",
    "merged_df.to_csv(\"reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dcd03df5-23fe-4a0a-9921-ea14e188e084",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Person</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Date of Experience</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>One of the worst airline ever ever</td>\n",
       "      <td>sharam Salih</td>\n",
       "      <td>Friday, January 26, 2024 at 12:22:25 AM</td>\n",
       "      <td>Date of experience: December 28, 2023</td>\n",
       "      <td>One of the worst airline ever\\nShocked with 2 ...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>They need to build stronger aircraft or…</td>\n",
       "      <td>C L</td>\n",
       "      <td>Monday, January 22, 2024 at 11:36:05 PM</td>\n",
       "      <td>Date of experience: January 21, 2024</td>\n",
       "      <td>They need to build stronger aircraft or someth...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>Avoid!! get insulted with customer service</td>\n",
       "      <td>Senhao Zhang</td>\n",
       "      <td>Sunday, January 21, 2024 at 11:12:17 PM</td>\n",
       "      <td>Date of experience: January 21, 2024</td>\n",
       "      <td>The guy who picked up my was so rude and even ...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rated 4 out of 5 stars</td>\n",
       "      <td>Cancelled flight</td>\n",
       "      <td>John Mc.</td>\n",
       "      <td>Thursday, January 25, 2024 at 12:52:51 AM</td>\n",
       "      <td>Date of experience: January 07, 2024</td>\n",
       "      <td>I recently had a flight cancellation due to fo...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>I love travelling with Aer Lingus</td>\n",
       "      <td>Mary Mckeegan</td>\n",
       "      <td>Friday, January 19, 2024 at 11:18:02 PM</td>\n",
       "      <td>Date of experience: January 19, 2024</td>\n",
       "      <td>I love travelling with Aer Lingus, no problem ...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Stars                                  Post Title  \\\n",
       "0  Rated 1 out of 5 stars          One of the worst airline ever ever   \n",
       "1  Rated 1 out of 5 stars    They need to build stronger aircraft or…   \n",
       "2  Rated 1 out of 5 stars  Avoid!! get insulted with customer service   \n",
       "3  Rated 4 out of 5 stars                            Cancelled flight   \n",
       "4  Rated 1 out of 5 stars           I love travelling with Aer Lingus   \n",
       "\n",
       "          Person                                Date Posted  \\\n",
       "0   sharam Salih    Friday, January 26, 2024 at 12:22:25 AM   \n",
       "1            C L    Monday, January 22, 2024 at 11:36:05 PM   \n",
       "2   Senhao Zhang    Sunday, January 21, 2024 at 11:12:17 PM   \n",
       "3       John Mc.  Thursday, January 25, 2024 at 12:52:51 AM   \n",
       "4  Mary Mckeegan    Friday, January 19, 2024 at 11:18:02 PM   \n",
       "\n",
       "                      Date of Experience  \\\n",
       "0  Date of experience: December 28, 2023   \n",
       "1   Date of experience: January 21, 2024   \n",
       "2   Date of experience: January 21, 2024   \n",
       "3   Date of experience: January 07, 2024   \n",
       "4   Date of experience: January 19, 2024   \n",
       "\n",
       "                                         Review Text       Query  \n",
       "0  One of the worst airline ever\\nShocked with 2 ...  aer lingus  \n",
       "1  They need to build stronger aircraft or someth...  aer lingus  \n",
       "2  The guy who picked up my was so rude and even ...  aer lingus  \n",
       "3  I recently had a flight cancellation due to fo...  aer lingus  \n",
       "4  I love travelling with Aer Lingus, no problem ...  aer lingus  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da967e42-ff36-41e0-936d-6356c1d1c714",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merging raw datasets (group portion)\n",
    "\n",
    "Here the raw training and testing datasets are created. The only steps that were performed were: \n",
    "- renaming columns\n",
    "- dropping unmatched columns\n",
    "- appending the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f132548-e396-41d0-9349-fe5d9934edd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pin_shien = pd.read_csv(\"pinshien_airline_scraped_data.csv\")\n",
    "karthik = pd.read_csv(\"karthik_airline_scraped_data.csv\")\n",
    "junming = pd.read_csv(\"junming_airline_scrapped_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4716aaa4-a1e8-45f4-8c74-0a1712bb1fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stars', 'Post Title', 'Person', 'Date Posted', 'Date of Experience',\n",
       "       'Review Text', 'Query'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "karthik.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32c308a1-6d5a-4fe0-869a-b79ab4c7409f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "karthik.drop(columns=[\"Post Title\", \"Date of Experience\", \"Person\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "971ae2cc-a495-4f51-9f2d-d5822e0b60ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Passenger Name', 'Review Date', 'Airline Name',\n",
       "       'Airline Average Rating', 'Cabin Flown', 'Passenger Overall Rating',\n",
       "       'Overall Value for Money', 'Seat and Cabin Space', 'Customer Service',\n",
       "       'In Flight Entertainment', 'Baggage Handling', 'Check-in Process',\n",
       "       'Meals and Beverages', 'Recommend Airline', 'Passenger Review Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin_shien.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc8e9a96-8bf4-44ac-8d76-54b1bd365fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pin_shien.drop(columns=[\"Airline Average Rating\", \"Cabin Flown\", \"Overall Value for Money\", \"Seat and Cabin Space\", \"Customer Service\", \"In Flight Entertainment\", \"Baggage Handling\", \"Check-in Process\", \"Meals and Beverages\", \"Recommend Airline\", \"Passenger Name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29027500-1fb5-45c0-a0d1-5c454b1d5df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pin_shien.rename(columns={\n",
    "    \"Review Date\": \"review_date\",\n",
    "    \"Airline Name\": \"airline_name\",\n",
    "    \"Passenger Overall Rating\": \"overall_rating\",\n",
    "    \"Passenger Review Text\": \"review_text\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfdf01df-9f6d-479b-94f1-8fde6f79bef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "karthik.rename(columns={\n",
    "    \"Person\": \"passenger_name\",\n",
    "    \"Date Posted\": \"review_date\",\n",
    "    \"Query\": \"airline_name\",\n",
    "    \"Stars\": \"overall_rating\",\n",
    "    \"Review Text\": \"review_text\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1eb46384-a158-4195-8ae8-3d4be69b3d21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>aircraft</th>\n",
       "      <th>travel_type</th>\n",
       "      <th>travel_class</th>\n",
       "      <th>route</th>\n",
       "      <th>date</th>\n",
       "      <th>seating_comfort</th>\n",
       "      <th>staff_service</th>\n",
       "      <th>food_quality</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>wifi</th>\n",
       "      <th>ground_service</th>\n",
       "      <th>value_for_money</th>\n",
       "      <th>recommended</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>review</th>\n",
       "      <th>airline_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>London Heathrow to Miami</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>Stinking nappies being changed in business ca...</td>\n",
       "      <td>british airways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Boston to Düsseldorf via London</td>\n",
       "      <td>January 2024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Worst service ever. Lost baggage because of d...</td>\n",
       "      <td>british airways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified</td>\n",
       "      <td>A350</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Sao Paulo to London Heathrow</td>\n",
       "      <td>January 2024</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>BA 246 21JAN 2023 Did not appreciate the unp...</td>\n",
       "      <td>british airways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified</td>\n",
       "      <td>A320</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>London Heathrow to Lisbon</td>\n",
       "      <td>January 2024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>Not a great experience. I could not check in ...</td>\n",
       "      <td>british airways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>London to Hong Kong</td>\n",
       "      <td>January 2024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>I was excited to fly BA as I'd not travelled ...</td>\n",
       "      <td>british airways</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status aircraft     travel_type    travel_class  \\\n",
       "0  ✅ Trip Verified       NaN  Family Leisure  Business Class   \n",
       "1  ✅ Trip Verified       NaN    Solo Leisure   Economy Class   \n",
       "2  ✅ Trip Verified      A350        Business   Economy Class   \n",
       "3  ✅ Trip Verified      A320  Couple Leisure   Economy Class   \n",
       "4     Not Verified       NaN  Family Leisure   Economy Class   \n",
       "\n",
       "                             route           date  seating_comfort  \\\n",
       "0         London Heathrow to Miami  December 2023              2.0   \n",
       "1  Boston to Düsseldorf via London   January 2024              1.0   \n",
       "2     Sao Paulo to London Heathrow   January 2024              3.0   \n",
       "3        London Heathrow to Lisbon   January 2024              1.0   \n",
       "4             London to Hong Kong    January 2024              1.0   \n",
       "\n",
       "   staff_service  food_quality  entertainment  wifi  ground_service  \\\n",
       "0            1.0           2.0            2.0   NaN             3.0   \n",
       "1            2.0           1.0            1.0   NaN             1.0   \n",
       "2            4.0           3.0            3.0   3.0             3.0   \n",
       "3            4.0           1.0            NaN   NaN             3.0   \n",
       "4            3.0           1.0            1.0   1.0             1.0   \n",
       "\n",
       "   value_for_money recommended  overall_rating  \\\n",
       "0                2          no               2   \n",
       "1                1          no               1   \n",
       "2                3          no               6   \n",
       "3                4          no               3   \n",
       "4                2          no               2   \n",
       "\n",
       "                                              review     airline_name  \n",
       "0   Stinking nappies being changed in business ca...  british airways  \n",
       "1   Worst service ever. Lost baggage because of d...  british airways  \n",
       "2    BA 246 21JAN 2023 Did not appreciate the unp...  british airways  \n",
       "3   Not a great experience. I could not check in ...  british airways  \n",
       "4   I was excited to fly BA as I'd not travelled ...  british airways  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junming.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54512019-c283-4bf4-b3c3-84e698f4d4e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "junming.rename(columns={\n",
    "    \"date\": \"review_date\",\n",
    "    \"review\": \"review_text\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6323c48e-ed82-4d34-8526-6139e16e3fef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['status', 'aircraft', 'travel_type', 'travel_class', 'route',\n",
       "       'review_date', 'seating_comfort', 'staff_service', 'food_quality',\n",
       "       'entertainment', 'wifi', 'ground_service', 'value_for_money',\n",
       "       'recommended', 'overall_rating', 'review_text', 'airline_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junming.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37bfecf2-88b5-411b-8b8c-9baeccc9708c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "junming.drop(columns=[\"status\", \"aircraft\", \"travel_type\", 'travel_class', 'route', 'seating_comfort', 'staff_service', 'food_quality',\n",
    "       'entertainment', 'wifi', 'ground_service', 'value_for_money',\n",
    "       'recommended'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e559aca-5c99-4b2b-847c-cd44ed0d7da7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>airline_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>Friday, January 26, 2024 at 12:22:25 AM</td>\n",
       "      <td>One of the worst airline ever\\nShocked with 2 ...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>Monday, January 22, 2024 at 11:36:05 PM</td>\n",
       "      <td>They need to build stronger aircraft or someth...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>Sunday, January 21, 2024 at 11:12:17 PM</td>\n",
       "      <td>The guy who picked up my was so rude and even ...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rated 4 out of 5 stars</td>\n",
       "      <td>Thursday, January 25, 2024 at 12:52:51 AM</td>\n",
       "      <td>I recently had a flight cancellation due to fo...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>Friday, January 19, 2024 at 11:18:02 PM</td>\n",
       "      <td>I love travelling with Aer Lingus, no problem ...</td>\n",
       "      <td>aer lingus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82173</th>\n",
       "      <td>1</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>Flight was cancelled, which is ok if you got ...</td>\n",
       "      <td>WestJet Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82174</th>\n",
       "      <td>1</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>Flight was cancelled, which is ok if you got ...</td>\n",
       "      <td>WestJet Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82175</th>\n",
       "      <td>1</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>Flight was cancelled, which is ok if you got ...</td>\n",
       "      <td>WestJet Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82176</th>\n",
       "      <td>1</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>Flight was cancelled, which is ok if you got ...</td>\n",
       "      <td>WestJet Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82177</th>\n",
       "      <td>1</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>Flight was cancelled, which is ok if you got ...</td>\n",
       "      <td>WestJet Airlines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82178 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               overall_rating                                review_date  \\\n",
       "0      Rated 1 out of 5 stars    Friday, January 26, 2024 at 12:22:25 AM   \n",
       "1      Rated 1 out of 5 stars    Monday, January 22, 2024 at 11:36:05 PM   \n",
       "2      Rated 1 out of 5 stars    Sunday, January 21, 2024 at 11:12:17 PM   \n",
       "3      Rated 4 out of 5 stars  Thursday, January 25, 2024 at 12:52:51 AM   \n",
       "4      Rated 1 out of 5 stars    Friday, January 19, 2024 at 11:18:02 PM   \n",
       "...                       ...                                        ...   \n",
       "82173                       1                              December 2023   \n",
       "82174                       1                              December 2023   \n",
       "82175                       1                              December 2023   \n",
       "82176                       1                              December 2023   \n",
       "82177                       1                              December 2023   \n",
       "\n",
       "                                             review_text      airline_name  \n",
       "0      One of the worst airline ever\\nShocked with 2 ...        aer lingus  \n",
       "1      They need to build stronger aircraft or someth...        aer lingus  \n",
       "2      The guy who picked up my was so rude and even ...        aer lingus  \n",
       "3      I recently had a flight cancellation due to fo...        aer lingus  \n",
       "4      I love travelling with Aer Lingus, no problem ...        aer lingus  \n",
       "...                                                  ...               ...  \n",
       "82173   Flight was cancelled, which is ok if you got ...  WestJet Airlines  \n",
       "82174   Flight was cancelled, which is ok if you got ...  WestJet Airlines  \n",
       "82175   Flight was cancelled, which is ok if you got ...  WestJet Airlines  \n",
       "82176   Flight was cancelled, which is ok if you got ...  WestJet Airlines  \n",
       "82177   Flight was cancelled, which is ok if you got ...  WestJet Airlines  \n",
       "\n",
       "[82178 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended_df = pd.concat([karthik, pin_shien, junming], ignore_index=True)\n",
    "appended_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "defcaca1-0d1e-4671-a082-ec81949c0c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_80, df_20 = train_test_split(appended_df, test_size=0.2, random_state=42)\n",
    "\n",
    "df_80.to_csv(\"training_data.csv\")\n",
    "df_20.to_csv(\"testing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "87206083-5b2d-48e1-a4a0-68671b5ea5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>airline_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23743</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>Monday, September 18, 2023 at 03:29:15 AM</td>\n",
       "      <td>EasyJet sent text at 4.00 am day of flight hom...</td>\n",
       "      <td>easyjet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82074</th>\n",
       "      <td>9</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>Its been a few years when I flew a lot in A...</td>\n",
       "      <td>Vistara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75513</th>\n",
       "      <td>Rated 5 out of 5 stars</td>\n",
       "      <td>Wednesday, September 6, 2023 at 01:58:27 AM</td>\n",
       "      <td>Useful</td>\n",
       "      <td>volotea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>Sunday, September 9, 2018 at 08:37:11 PM</td>\n",
       "      <td>one of the worst experiences with Air France e...</td>\n",
       "      <td>air france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26212</th>\n",
       "      <td>Rated 1 out of 5 stars</td>\n",
       "      <td>Monday, December 23, 2019 at 02:00:19 PM</td>\n",
       "      <td>Not a single star this airlines deserves .I lo...</td>\n",
       "      <td>egyptair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               overall_rating                                  review_date  \\\n",
       "23743  Rated 1 out of 5 stars    Monday, September 18, 2023 at 03:29:15 AM   \n",
       "82074                       9                                December 2023   \n",
       "75513  Rated 5 out of 5 stars  Wednesday, September 6, 2023 at 01:58:27 AM   \n",
       "4699   Rated 1 out of 5 stars     Sunday, September 9, 2018 at 08:37:11 PM   \n",
       "26212  Rated 1 out of 5 stars     Monday, December 23, 2019 at 02:00:19 PM   \n",
       "\n",
       "                                             review_text airline_name  \n",
       "23743  EasyJet sent text at 4.00 am day of flight hom...      easyjet  \n",
       "82074     Its been a few years when I flew a lot in A...      Vistara  \n",
       "75513                                             Useful      volotea  \n",
       "4699   one of the worst experiences with Air France e...   air france  \n",
       "26212  Not a single star this airlines deserves .I lo...     egyptair  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_80.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
